{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wikimapper import WikiMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the wikidata index \n",
    "The file has to be downloaded using the following [link](https://public.ukp.informatik.tu-darmstadt.de/wikimapper/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = WikiMapper(\"data/index_enwiki-latest.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CMU Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns names\n",
    "cmu_movie_cols = ['wikipedia_id', 'freebase_id', 'cmu_movie_title', 'release_date', 'box_office_revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "\n",
    "# Open movie dataset and remove 'freebase_id' since it is not available anymore\n",
    "# Add movie wikidata ID using the mapper\n",
    "cmu_movie_df = (pd.read_csv('data/movie.metadata.tsv', sep='\\t', header=None, names=cmu_movie_cols)\n",
    "                .drop(['freebase_id'], axis=1)\n",
    "                .assign(\n",
    "                    wikidata_id = lambda x: x.wikipedia_id.apply(lambda y: mapper.wikipedia_id_to_id(y))\n",
    "                )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find movies based on books / book series\n",
    "To find all movies that are based on books we run the following SPARQL query on the [Wikidata Query Service](https://query.wikidata.org/):\n",
    "\n",
    "<code>\n",
    "SELECT DISTINCT ?movie ?book\n",
    "  \n",
    "WHERE \n",
    "{\n",
    "\n",
    "  VALUES ?bookType { wd:Q47461344 wd:Q7725634 wd:Q571 wd:Q14406742 wd:Q21198342 wd:Q277759}\n",
    "\n",
    "  VALUES ?movieType { wd:Q11424 wd:Q506240 }\n",
    "  \n",
    "  ?book wdt:P31 ?bookType.   \n",
    "\n",
    "  ?movie wdt:P31 ?movieType;          \n",
    "        \n",
    "        wdt:P144 ?book.\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "</code>\n",
    "\n",
    "It searches for instances of `film` or `television film` that are based on an instance of `literary work`, `written work`, `book`, `comic book series`, `manga series` or `book series`. This query gives a csv file which can be found in `data/raw_wiki/raw_movie_book.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the csv file we just created and extract the wikidata ID of movies and their corresponding book.\n",
    "movie_book_df = (pd.read_csv('data/raw_wiki/raw_movie_book.csv')\n",
    "                    .assign(\n",
    "                        movie_wikidata_id = lambda x: x.movie.str.split('/').str[-1],\n",
    "                        book_wikidata_id = lambda x: x.book.str.split('/').str[-1],\n",
    "                    )\n",
    "                    .drop(['movie', 'book'], axis=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the CMU dataframe with the movie_book_df containing the wikidata ID\n",
    "movie_book_df = (movie_book_df.merge(cmu_movie_df, left_on='movie_wikidata_id', right_on='wikidata_id', how='left')\n",
    "              .query('wikipedia_id.notnull()')\n",
    "              .reset_index(drop=True)\n",
    "              .assign(movie_wikipedia_id = lambda x: x.wikipedia_id.astype(int))\n",
    "              .loc[:, ['movie_wikipedia_id', 'book_wikidata_id']]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_wikipedia_id</th>\n",
       "      <th>book_wikidata_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18920019</td>\n",
       "      <td>Q480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21447227</td>\n",
       "      <td>Q480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2205704</td>\n",
       "      <td>Q480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7379134</td>\n",
       "      <td>Q480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10117133</td>\n",
       "      <td>Q480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>9767560</td>\n",
       "      <td>Q120669834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>1750951</td>\n",
       "      <td>Q123168810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>61191</td>\n",
       "      <td>Q121775426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>6851697</td>\n",
       "      <td>Q122186265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>27949074</td>\n",
       "      <td>Q122661363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_wikipedia_id book_wikidata_id\n",
       "0               18920019             Q480\n",
       "1               21447227             Q480\n",
       "2                2205704             Q480\n",
       "3                7379134             Q480\n",
       "4               10117133             Q480\n",
       "...                  ...              ...\n",
       "4677             9767560       Q120669834\n",
       "4678             1750951       Q123168810\n",
       "4679               61191       Q121775426\n",
       "4680             6851697       Q122186265\n",
       "4681            27949074       Q122661363\n",
       "\n",
       "[4682 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movie_book_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get information about books\n",
    "To later on be able to merge the books with goodreads data get title and author from [Wikidata Query Service](https://query.wikidata.org/). The 'query_string' must be replaced with the output of the next code cell which gives all the wikidata ID of the books we are looking for.\n",
    "<code>\n",
    "\n",
    "SELECT DISTINCT\n",
    "\n",
    "  ?book ?bookLabel\n",
    "\n",
    "  ?title\n",
    "\n",
    "  ?authorLabel\n",
    "\n",
    "  ?pubdate\n",
    "  \n",
    "WHERE \n",
    "{\n",
    "\n",
    "  VALUES ?book { query_string }\n",
    "\n",
    "  OPTIONAL { ?book wdt:P1476 ?title. }\n",
    "  \n",
    "  OPTIONAL { ?book wdt:P50 ?author. }\n",
    "\n",
    "  OPTIONAL { ?book wdt:P577 ?pubdate. }\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "\n",
    "</code>\n",
    "\n",
    "This query gives a csv file containing data of books, which can be found in `data/raw_wiki/wikidata_book.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the output of this cell into 'query_string' within the above query\n",
    "query_string = \" \".join([f'wd:{wikidata_id}' for wikidata_id in movie_book_df.book_wikidata_id.unique()])\n",
    "print(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['awardLabel', 'formLabel', 'genreLabel', 'instanceofLabel', 'seriesLabel'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied data analysis/ada-2023-project-team0110/data_wrangling.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m categories \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfiction\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mnovel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshort novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnovella\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mserialized fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshort story\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwar fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmagic realist fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmetafiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscience fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msuspense in literature\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhorror novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhorror fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcrime fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpsychological thriller\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mspeculative/fantastic fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madventure fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdetective fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnoir fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpolitical novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvampire fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdystopian fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msocial science fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtechno-thriller\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mthriller\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfantasy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGothic novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpicaresque novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmystery fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpost-apocalyptic fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mphilosophical fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mromantic fiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBildungsroman\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mroman à clef\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomedy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblack comedy\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnon_fiction\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mnonfiction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmemoir\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautobiography\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbiographical novel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbiography\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39messay\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcomedy\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mcomedy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblack comedy\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m book_wikidata_df \u001b[39m=\u001b[39m (pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/raw_wiki/wikidata_book.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                     \u001b[39m.\u001b[39;49massign(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                             book_wikidata_id \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mbook\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mstr[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                             year \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m x: pd\u001b[39m.\u001b[39;49mto_datetime(x\u001b[39m.\u001b[39;49mpubdate, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcoerce\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39;49myear\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mInt64\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                     \u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mbook\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                     \u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mbook_wikidata_id\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                     \u001b[39m.\u001b[39;49magg(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                             title \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mNamedAgg(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbookLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49mmode),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                             author \u001b[39m=\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39mauthorLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfirst\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                             year \u001b[39m=\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfirst\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                             instance_of \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mNamedAgg(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minstanceofLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49mget_list),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                             form \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mNamedAgg(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mformLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49mget_list),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                             genre \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mNamedAgg(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgenreLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49mget_list),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                             award \u001b[39m=\u001b[39;49m pd\u001b[39m.\u001b[39;49mNamedAgg(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mawardLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49mget_list),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                             series \u001b[39m=\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39mseriesLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfirst\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                     \u001b[39m.\u001b[39massign(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                         part_of_series \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mseries\u001b[39m.\u001b[39mnotnull()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                         is_literary_work \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39minstance_of\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mliterary work\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                         is_written_work \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39minstance_of\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mwritten work\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                         is_comic_book_seris \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39minstance_of\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mcomic book series\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                         is_book_series \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39minstance_of\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mbook series\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                         is_manga_series \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39minstance_of\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mmanga series\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                         is_novel \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mform\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mnovel\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                         is_short_story \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mform\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mshort story\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),    \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                         is_play \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mform\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mfiction\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                         is_novella \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mform\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39m'\u001b[39m\u001b[39mnovella\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m y)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m                         is_fiction \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mfiction\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                         is_non_fiction \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mnon_fiction\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m                         is_children \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mchildren\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m                         is_historical \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mhistorical\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                         is_drama \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mdrama\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                         is_anime \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39manime\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                         is_fantasy \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mfantasy\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m                         is_science_fiction \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mscience_fiction\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m                         is_horror \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mhorror\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                         is_thriller \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mthriller\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                         is_detective \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mdetective\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                         is_satire \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39msatire\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m                         is_comedy \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mgenre\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)\u001b[39m.\u001b[39mintersection(categories[\u001b[39m'\u001b[39m\u001b[39mcomedy\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                         won_price \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39maward\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m y: \u001b[39mlen\u001b[39m(y) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m                     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m                     \u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39minstance_of\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mform\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgenre\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romain/Documents/EPFL/2-MASTER/MA-3/Applied%20data%20analysis/ada-2023-project-team0110/data_wrangling.ipynb#X14sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m book_wikidata_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdataset/book_metadata.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1269\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m   1268\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m-> 1269\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m   1270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:163\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    164\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    165\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:403\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m     selected_obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selected_obj\n\u001b[1;32m    401\u001b[0m     selection \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selection\n\u001b[0;32m--> 403\u001b[0m arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m, selected_obj, arg)\n\u001b[1;32m    405\u001b[0m is_groupby \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[1;32m    406\u001b[0m context_manager: ContextManager\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:535\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    534\u001b[0m         cols_sorted \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(safe_sort(\u001b[39mlist\u001b[39m(cols)))\n\u001b[0;32m--> 535\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00mcols_sorted\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    537\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['awardLabel', 'formLabel', 'genreLabel', 'instanceofLabel', 'seriesLabel'] do not exist\""
     ]
    }
   ],
   "source": [
    "def get_list(series: pd.Series) -> list:\n",
    "    return list(set(series.dropna().tolist()))\n",
    "\n",
    "def mode(x: pd.Series) -> pd.Series:\n",
    "    modes = x.mode()\n",
    "    if len(modes) > 0:\n",
    "        return modes.iloc[0]\n",
    "    return None\n",
    "\n",
    "categories = {\n",
    "    'fiction': {'novel', 'short novel', 'novella', 'serialized fiction', 'short story', 'war fiction', 'magic realist fiction', 'metafiction', 'science fiction', 'suspense in literature', 'horror novel', 'horror fiction', 'crime fiction', 'psychological thriller', 'speculative/fantastic fiction', 'adventure fiction', 'detective fiction', 'noir fiction', 'political novel', 'vampire fiction', 'dystopian fiction', 'social science fiction', 'techno-thriller', 'thriller', 'fantasy', 'Gothic novel', 'picaresque novel', 'mystery fiction', 'post-apocalyptic fiction', 'philosophical fiction', 'romantic fiction', 'Bildungsroman', 'roman à clef', 'comedy', 'black comedy'},\n",
    "    'non_fiction': {'nonfiction', 'memoir', 'autobiography', 'biographical novel', 'biography', 'essay'},\n",
    "    'children': {'children\\'s literature', 'children\\'s fiction', 'young adult fiction', 'children\\'s novel'},\n",
    "    'historical': {'historical fiction', 'historical novel'},\n",
    "    'drama': {'play', 'drama', 'tragedy'},\n",
    "    'anime': {'adventure anime and manga', 'drama anime and manga'},\n",
    "    'fantasy': {'magic realist fiction', 'fantasy', 'vampire fiction', 'fairy tale'},\n",
    "    'science_fiction': {'science fiction', 'dystopian fiction', 'social science fiction', 'techno-thriller', 'post-apocalyptic fiction'},\n",
    "    'horror': {'horror novel', 'horror fiction'},\n",
    "    'thriller': {'psychological thriller', 'thriller'},\n",
    "    'detective': {'detective fiction', 'noir fiction', 'mystery fiction', 'cloak and dagger novel'},\n",
    "    'satire': {'satire', 'satirical fiction', 'metafiction'},\n",
    "    'comedy': {'comedy', 'black comedy'},\n",
    "}\n",
    "\n",
    "book_wikidata_df = (pd.read_csv('data/raw_wiki/wikidata_book.csv')\n",
    "                    .assign(\n",
    "                            book_wikidata_id = lambda x: x.book.str.split('/').str[-1],\n",
    "                            year = lambda x: pd.to_datetime(x.pubdate, errors='coerce').dt.year.astype('Int64'),\n",
    "                    )\n",
    "                    .drop(['book'], axis=1)\n",
    "                    .groupby('book_wikidata_id')\n",
    "                    .agg(\n",
    "                            title = pd.NamedAgg(column='bookLabel', aggfunc=mode),\n",
    "                            author = ('authorLabel', 'first'),\n",
    "                            year = ('year', 'first'),\n",
    "                            instance_of = pd.NamedAgg(column='instanceofLabel', aggfunc=get_list),\n",
    "                            form = pd.NamedAgg(column='formLabel', aggfunc=get_list),\n",
    "                            genre = pd.NamedAgg(column='genreLabel', aggfunc=get_list),\n",
    "                            award = pd.NamedAgg(column='awardLabel', aggfunc=get_list),\n",
    "                            series = ('seriesLabel', 'first'),\n",
    "                        )\n",
    "                    .assign(\n",
    "                        part_of_series = lambda x: x.series.notnull().astype(int),\n",
    "                        is_literary_work = lambda x: x.instance_of.apply(lambda y: 'literary work' in y).astype(int),\n",
    "                        is_written_work = lambda x: x.instance_of.apply(lambda y: 'written work' in y).astype(int),\n",
    "                        is_comic_book_seris = lambda x: x.instance_of.apply(lambda y: 'comic book series' in y).astype(int),\n",
    "                        is_book_series = lambda x: x.instance_of.apply(lambda y: 'book series' in y).astype(int),\n",
    "                        is_manga_series = lambda x: x.instance_of.apply(lambda y: 'manga series' in y).astype(int),\n",
    "                        is_novel = lambda x: x.form.apply(lambda y: 'novel' in y).astype(int),\n",
    "                        is_short_story = lambda x: x.form.apply(lambda y: 'short story' in y).astype(int),    \n",
    "                        is_play = lambda x: x.form.apply(lambda y: 'fiction' in y).astype(int),\n",
    "                        is_novella = lambda x: x.form.apply(lambda y: 'novella' in y).astype(int),\n",
    "                        is_fiction = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['fiction'])) > 0).astype(int),\n",
    "                        is_non_fiction = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['non_fiction'])) > 0).astype(int),\n",
    "                        is_children = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['children'])) > 0).astype(int),\n",
    "                        is_historical = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['historical'])) > 0).astype(int),\n",
    "                        is_drama = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['drama'])) > 0).astype(int),\n",
    "                        is_anime = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['anime'])) > 0).astype(int),\n",
    "                        is_fantasy = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['fantasy'])) > 0).astype(int),\n",
    "                        is_science_fiction = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['science_fiction'])) > 0).astype(int),\n",
    "                        is_horror = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['horror'])) > 0).astype(int),\n",
    "                        is_thriller = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['thriller'])) > 0).astype(int),\n",
    "                        is_detective = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['detective'])) > 0).astype(int),\n",
    "                        is_satire = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['satire'])) > 0).astype(int),\n",
    "                        is_comedy = lambda x: x.genre.apply(lambda y: len(set(y).intersection(categories['comedy'])) > 0).astype(int),\n",
    "                        won_price = lambda x: x.award.apply(lambda y: len(y) > 0).astype(int),\n",
    "                    )\n",
    "                    .drop(['instance_of', 'form', 'genre', 'award', 'series'], axis=1)\n",
    ")\n",
    "\n",
    "book_wikidata_df.to_csv('dataset/book_metadata.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_meta_df = (pd.read_csv('data/wikidata_book.csv')\n",
    "                    .assign(\n",
    "                        book_wikidata_id = lambda x: x.book.str.split('/').str[-1]\n",
    "                        )\n",
    "                    .drop(['book'], axis=1)\n",
    "                    .rename(columns={'authorLabel': 'author', 'title': 'title_wikidata'})\n",
    "                    .melt(id_vars=['book_wikidata_id', 'author'], value_vars=['bookLabel', 'title_wikidata'], value_name='title')\n",
    "                    .drop(columns=['variable'])\n",
    "                    .query('title.notnull()')\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join with Goodreads Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goodreads_df_list = []\n",
    "goodreads_df_list.append(pd.read_csv('archive/book1-100k.csv'))\n",
    "for i in range(1,20):\n",
    "    goodreads_df_list.append(pd.read_csv(f'archive/book{i*100}k-{(i+1)*100}k.csv'))\n",
    "goodreads_df_list.append(pd.read_csv('archive/book2000k-3000k.csv'))\n",
    "goodreads_df_list.append(pd.read_csv('archive/book3000k-4000k.csv'))\n",
    "goodreads_df_list.append(pd.read_csv('archive/book4000k-5000k.csv'))\n",
    "goodreads_df = (pd.concat(goodreads_df_list)\n",
    "                .assign(\n",
    "                    n_pages = lambda x: x.pagesNumber.fillna(x.PagesNumber),\n",
    "                    n_ratings = lambda x: x.RatingDistTotal.str.split(':').str[1].astype(int)\n",
    "                    )\n",
    "                .rename(columns={'Id': 'goodreads_id', 'Authors': 'authors', 'Name': 'title', 'CountsOfReview': 'n_reviews', 'Rating': 'rating', 'PublishYear': 'year', 'Description': 'summary'})\n",
    "                .loc[:, ['goodreads_id', 'title', 'authors', 'year', 'n_pages', 'n_ratings', 'n_reviews', 'rating', 'summary']]\n",
    "                )\n",
    "goodreads_meta_df = (goodreads_df.assign(\n",
    "                        author = lambda x: x.authors.str.split('/'),\n",
    "                     )\n",
    "                     .loc[:, ['goodreads_id', 'title', 'author']]\n",
    "                     .explode('author')\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title_series: pd.Series) -> pd.Series:\n",
    "    return (title_series\n",
    "            .str.split('(').str[0]\n",
    "            .str.split(':').str[0]\n",
    "            .str.lower()\n",
    "            .str.replace('and', '&')\n",
    "            .str.replace('.', '')\n",
    "            .str.replace(\"'\", '')\n",
    "            .str.replace('-', ' ')\n",
    "            .str.replace(r'\\s+', ' ', regex=True)\n",
    "            .str.strip()\n",
    "    )\n",
    "\n",
    "def clean_author(author_series: pd.Series) -> pd.Series:\n",
    "    initial_letter = (author_series\n",
    "                      .str.strip()\n",
    "                      .str[0]\n",
    "                      .str.lower())\n",
    "    last_name = (author_series\n",
    "                 .str.split(r\"(\\s|-|')\", regex=True)\n",
    "                 .str[-1]\n",
    "                 .str.replace('.', '')\n",
    "                 .str.replace(\"'\", '')\n",
    "                 .str.replace(r'\\s+', ' ', regex=True)\n",
    "                 .str.strip()\n",
    "                 .str.lower()\n",
    "                 )\n",
    "    return initial_letter + \" \" + last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_meta_df = (goodreads_meta_df\n",
    "                        .assign(\n",
    "                            title_clean = lambda x: clean_title(x.title),\n",
    "                            author_clean = lambda x: clean_author(x.author)\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_meta_df = (wikidata_meta_df\n",
    "                    .assign(\n",
    "                        title_clean = lambda x: clean_title(x.title),\n",
    "                        author_clean = lambda x: clean_author(x.author)\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_to_goodreads = (wikidata_meta_df\n",
    "                            .merge(goodreads_meta_df, on=['title_clean', 'author_clean'], how='left')\n",
    "                            .query('goodreads_id.notnull()')\n",
    "                            .assign(goodreads_id = lambda x: x.goodreads_id.astype(int))\n",
    "                            .loc[:, ['book_wikidata_id', 'goodreads_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_goodreads_df = (wikidata_to_goodreads\n",
    "                            .merge(goodreads_df, on='goodreads_id', how='inner')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings_df = (relevant_goodreads_df\n",
    " .groupby('book_wikidata_id')\n",
    " .agg(\n",
    "     title = pd.NamedAgg(column='title', aggfunc=mode),\n",
    "     author = pd.NamedAgg(column='authors', aggfunc=mode),\n",
    "     year = ('year', 'min'),\n",
    "     n_pages = ('n_pages', 'median'),\n",
    "     n_ratings = ('n_ratings', 'max'),\n",
    "     n_reviews = ('n_reviews', 'max'),\n",
    "     rating = ('rating', 'median'),\n",
    "     summary = pd.NamedAgg(column='summary', aggfunc=mode)\n",
    " )\n",
    ".assign(\n",
    "    n_pages = lambda x: x.n_pages.astype(int),\n",
    ")\n",
    ".reset_index()\n",
    ")\n",
    "book_ratings_df.to_csv('dataset/book_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_book_summaries_df = pd.read_csv('booksummaries/booksummaries.txt', \n",
    "                                    sep='\\t', header=None, \n",
    "                                    names=['wikipedia_id', 'freebase_id', 'title', 'author', 'pub_date', 'genres', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_book_summaries_df = (cmu_book_summaries_df\n",
    "                        .drop(['freebase_id'], axis=1)\n",
    "                        .assign(\n",
    "                                wikidata_id = lambda x: x.wikipedia_id.apply(lambda y: mapper.wikipedia_id_to_id(y))\n",
    "                                )\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_book_df\n",
    " .merge(cmu_book_summaries_df, left_on='book_wikidata_id', right_on='wikidata_id', how='inner')\n",
    " .loc[:,['book_wikidata_id', 'title', 'author', 'pub_date', 'genres', 'summary']]\n",
    " .to_csv('dataset/book_summaries.csv', index=False)\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_book_df.to_csv('dataset/movie_book.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean CMU movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_wikipedia_id</th>\n",
       "      <th>cmu_movie_title</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>movie_box_office_revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>movie_languages</th>\n",
       "      <th>movie_countries</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_wikidata_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Q261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "      <td>Q16250726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "      <td>Q4978832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>Q7995657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q869644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q6819873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81737</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Ireland, United Kingdom]</td>\n",
       "      <td>[Biographical film, Drama, Documentary]</td>\n",
       "      <td>Q12125420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Satire, Comedy]</td>\n",
       "      <td>Q4770308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81739</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[Japanese Language]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>[Science Fiction, Japanese Movies, Adventure, ...</td>\n",
       "      <td>Q2663931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81740</th>\n",
       "      <td>12476867</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Canada]</td>\n",
       "      <td>[Thriller, Horror, Slasher, Teen]</td>\n",
       "      <td>Q7578560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_wikipedia_id                                    cmu_movie_title  \\\n",
       "0                  975900                                     Ghosts of Mars   \n",
       "1                 3196793  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2                28463795                                        Brun bitter   \n",
       "3                 9363483                                   White Of The Eye   \n",
       "4                  261236                                  A Woman in Flames   \n",
       "...                   ...                                                ...   \n",
       "81736            35228177                           Mermaids: The Body Found   \n",
       "81737            34980460                                            Knuckle   \n",
       "81738             9971909                                  Another Nice Mess   \n",
       "81739              913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "81740            12476867                                            Spliced   \n",
       "\n",
       "      movie_release_date  movie_box_office_revenue  runtime  \\\n",
       "0             2001-08-24                14010832.0     98.0   \n",
       "1             2000-02-16                       NaN     95.0   \n",
       "2                   1988                       NaN     83.0   \n",
       "3                   1987                       NaN    110.0   \n",
       "4                   1983                       NaN    106.0   \n",
       "...                  ...                       ...      ...   \n",
       "81736         2011-03-19                       NaN    120.0   \n",
       "81737         2011-01-21                       NaN     96.0   \n",
       "81738         1972-09-22                       NaN     66.0   \n",
       "81739         1992-05-21                       NaN    150.0   \n",
       "81740               2002                       NaN     86.0   \n",
       "\n",
       "            movie_languages             movie_countries  \\\n",
       "0        [English Language]  [United States of America]   \n",
       "1        [English Language]  [United States of America]   \n",
       "2      [Norwegian Language]                    [Norway]   \n",
       "3        [English Language]            [United Kingdom]   \n",
       "4         [German Language]                   [Germany]   \n",
       "...                     ...                         ...   \n",
       "81736    [English Language]  [United States of America]   \n",
       "81737    [English Language]   [Ireland, United Kingdom]   \n",
       "81738    [English Language]  [United States of America]   \n",
       "81739   [Japanese Language]                     [Japan]   \n",
       "81740    [English Language]                    [Canada]   \n",
       "\n",
       "                                            movie_genres movie_wikidata_id  \n",
       "0      [Thriller, Science Fiction, Horror, Adventure,...           Q261700  \n",
       "1       [Mystery, Biographical film, Drama, Crime Drama]         Q16250726  \n",
       "2                                 [Crime Fiction, Drama]          Q4978832  \n",
       "3      [Thriller, Erotic thriller, Psychological thri...          Q7995657  \n",
       "4                                                [Drama]           Q869644  \n",
       "...                                                  ...               ...  \n",
       "81736                                            [Drama]          Q6819873  \n",
       "81737            [Biographical film, Drama, Documentary]         Q12125420  \n",
       "81738                                   [Satire, Comedy]          Q4770308  \n",
       "81739  [Science Fiction, Japanese Movies, Adventure, ...          Q2663931  \n",
       "81740                  [Thriller, Horror, Slasher, Teen]          Q7578560  \n",
       "\n",
       "[81741 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open the CMU dataset\n",
    "movie_df = pd.read_csv(\"data/movie.metadata.tsv\", sep='\\t',names=['movie_wikipedia_id', 'freebase_id', 'cmu_movie_title', 'movie_release_date', \n",
    "                                                                  'movie_box_office_revenue', 'runtime', 'movie_languages', 'movie_countries', \n",
    "                                                                  'movie_genres']).drop('freebase_id', axis=1).assign(\n",
    "                    movie_wikidata_id = lambda x: x.movie_wikipedia_id.apply(lambda y: mapper.wikipedia_id_to_id(y))\n",
    "                )\n",
    "\n",
    "#Clean columns\n",
    "movie_df['movie_genres'] = movie_df['movie_genres'].apply(lambda x: np.take(x.split('\"'), np.linspace(3,len(x.split('\"'))-2, int((len(x.split('\"'))-1)/4)).tolist()))\n",
    "movie_df['movie_languages'] = movie_df['movie_languages'].apply(lambda x: np.take(x.split('\"'), np.linspace(3,len(x.split('\"'))-2, int((len(x.split('\"'))-1)/4)).tolist()))\n",
    "movie_df['movie_countries'] = movie_df['movie_countries'].apply(lambda x: np.take(x.split('\"'), np.linspace(3,len(x.split('\"'))-2, int((len(x.split('\"'))-1)/4)).tolist()))\n",
    "display(movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add movies ratings to CMU movies dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add movies ratings from IMDB to the CMU dataset, use the following query on [Wikidata Query Service](https://query.wikidata.org/).\n",
    "First, we look for the IMDB ID of the movies.  \n",
    "\n",
    "<code>\n",
    "\n",
    "SELECT\n",
    "\n",
    "?movie \n",
    "\n",
    "?IMDB_ID \n",
    "\n",
    "WHERE \n",
    "\n",
    "{\n",
    "\n",
    "  VALUES ?movieType { wd:Q11424 wd:Q506240 }\n",
    "  \n",
    "  ?movie wdt:P31 ?movieType.\n",
    "\n",
    "  ?movie wdt:P345 ?IMDB_ID.\n",
    "  \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "  \n",
    "}\n",
    "\n",
    "</code>\n",
    "\n",
    "This query gives a csv file containing IMDB ID and wikidata ID, which can be found in `data/raw_wiki/IMDb_id.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-commercial IMDb rating data set can be found [here](https://developer.imdb.com/non-commercial-datasets/). It contains the movie ratings (score out of 10) with the corresponding IMDb_ID. This dataset is in `data/IMDb_ratings.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>movie_rating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000002</td>\n",
       "      <td>5.8</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000004</td>\n",
       "      <td>5.5</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_id  movie_rating  numVotes\n",
       "0  0000001           5.7      2004\n",
       "1  0000002           5.8       269\n",
       "2  0000003           6.5      1902\n",
       "3  0000004           5.5       178\n",
       "4  0000005           6.2      2685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open IMDb_ratings file and clean the ID (remove 'tt' at the beginning)\n",
    "ratings_df = pd.read_csv('data/IMDb_ratings.tsv', sep='\\t').rename(columns={\"tconst\" : \"imdb_id\", \"averageRating\" : \"movie_rating\"})\n",
    "ratings_df['imdb_id'] = ratings_df['imdb_id'].str[2:]\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the movie ratings to the movie dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_wikipedia_id</th>\n",
       "      <th>cmu_movie_title</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>movie_box_office_revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>movie_languages</th>\n",
       "      <th>movie_countries</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_wikidata_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>movie_rating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Q261700</td>\n",
       "      <td>0228333</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "      <td>Q16250726</td>\n",
       "      <td>0245916</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "      <td>Q4978832</td>\n",
       "      <td>0094806</td>\n",
       "      <td>5.6</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>Q7995657</td>\n",
       "      <td>0094320</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q869644</td>\n",
       "      <td>0083949</td>\n",
       "      <td>6.0</td>\n",
       "      <td>621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81906</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q6819873</td>\n",
       "      <td>1816585</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81907</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Ireland, United Kingdom]</td>\n",
       "      <td>[Biographical film, Drama, Documentary]</td>\n",
       "      <td>Q12125420</td>\n",
       "      <td>1606259</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81908</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Satire, Comedy]</td>\n",
       "      <td>Q4770308</td>\n",
       "      <td>0362411</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81909</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[Japanese Language]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>[Science Fiction, Japanese Movies, Adventure, ...</td>\n",
       "      <td>Q2663931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>12476867</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Canada]</td>\n",
       "      <td>[Thriller, Horror, Slasher, Teen]</td>\n",
       "      <td>Q7578560</td>\n",
       "      <td>0354216</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1766.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81911 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_wikipedia_id                                    cmu_movie_title  \\\n",
       "0                  975900                                     Ghosts of Mars   \n",
       "1                 3196793  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2                28463795                                        Brun bitter   \n",
       "3                 9363483                                   White Of The Eye   \n",
       "4                  261236                                  A Woman in Flames   \n",
       "...                   ...                                                ...   \n",
       "81906            35228177                           Mermaids: The Body Found   \n",
       "81907            34980460                                            Knuckle   \n",
       "81908             9971909                                  Another Nice Mess   \n",
       "81909              913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "81910            12476867                                            Spliced   \n",
       "\n",
       "      movie_release_date  movie_box_office_revenue  runtime  \\\n",
       "0             2001-08-24                14010832.0     98.0   \n",
       "1             2000-02-16                       NaN     95.0   \n",
       "2                   1988                       NaN     83.0   \n",
       "3                   1987                       NaN    110.0   \n",
       "4                   1983                       NaN    106.0   \n",
       "...                  ...                       ...      ...   \n",
       "81906         2011-03-19                       NaN    120.0   \n",
       "81907         2011-01-21                       NaN     96.0   \n",
       "81908         1972-09-22                       NaN     66.0   \n",
       "81909         1992-05-21                       NaN    150.0   \n",
       "81910               2002                       NaN     86.0   \n",
       "\n",
       "            movie_languages             movie_countries  \\\n",
       "0        [English Language]  [United States of America]   \n",
       "1        [English Language]  [United States of America]   \n",
       "2      [Norwegian Language]                    [Norway]   \n",
       "3        [English Language]            [United Kingdom]   \n",
       "4         [German Language]                   [Germany]   \n",
       "...                     ...                         ...   \n",
       "81906    [English Language]  [United States of America]   \n",
       "81907    [English Language]   [Ireland, United Kingdom]   \n",
       "81908    [English Language]  [United States of America]   \n",
       "81909   [Japanese Language]                     [Japan]   \n",
       "81910    [English Language]                    [Canada]   \n",
       "\n",
       "                                            movie_genres movie_wikidata_id  \\\n",
       "0      [Thriller, Science Fiction, Horror, Adventure,...           Q261700   \n",
       "1       [Mystery, Biographical film, Drama, Crime Drama]         Q16250726   \n",
       "2                                 [Crime Fiction, Drama]          Q4978832   \n",
       "3      [Thriller, Erotic thriller, Psychological thri...          Q7995657   \n",
       "4                                                [Drama]           Q869644   \n",
       "...                                                  ...               ...   \n",
       "81906                                            [Drama]          Q6819873   \n",
       "81907            [Biographical film, Drama, Documentary]         Q12125420   \n",
       "81908                                   [Satire, Comedy]          Q4770308   \n",
       "81909  [Science Fiction, Japanese Movies, Adventure, ...          Q2663931   \n",
       "81910                  [Thriller, Horror, Slasher, Teen]          Q7578560   \n",
       "\n",
       "       imdb_id  movie_rating  numVotes  \n",
       "0      0228333           4.9   56854.0  \n",
       "1      0245916           6.0      69.0  \n",
       "2      0094806           5.6      40.0  \n",
       "3      0094320           6.1    2888.0  \n",
       "4      0083949           6.0     621.0  \n",
       "...        ...           ...       ...  \n",
       "81906  1816585           4.6    1710.0  \n",
       "81907  1606259           6.8    3191.0  \n",
       "81908  0362411           5.8     110.0  \n",
       "81909      NaN           NaN       NaN  \n",
       "81910  0354216           4.3    1766.0  \n",
       "\n",
       "[81911 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open IMDb_id and merge with ratings\n",
    "IMDb_ID_df = pd.read_csv('data/raw_wiki/IMDb_id.csv').assign(wikidata_id = lambda x: x.movie.str.split('/').str[-1]).assign(imdb_id = lambda x: x['IMDB_ID'].str[2:]).drop(['movie', 'IMDB_ID'], axis=1)\n",
    "IMDb_ID_df = IMDb_ID_df.merge(ratings_df, on='imdb_id', how='left').copy()\n",
    "IMDb_ID_df.head(5)\n",
    "\n",
    "# Merge rating to movie_df using the wikidata_id\n",
    "final_movie_df = movie_df.merge(IMDb_ID_df, left_on='movie_wikidata_id', right_on='wikidata_id', how='left').drop('wikidata_id', axis=1)\n",
    "display(final_movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's modify the 'release_date' column to keep only the release year for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_wikipedia_id</th>\n",
       "      <th>cmu_movie_title</th>\n",
       "      <th>movie_box_office_revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>movie_languages</th>\n",
       "      <th>movie_countries</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_wikidata_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>movie_rating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>movie_release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Q261700</td>\n",
       "      <td>0228333</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "      <td>Q16250726</td>\n",
       "      <td>0245916</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "      <td>Q4978832</td>\n",
       "      <td>0094806</td>\n",
       "      <td>5.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>Q7995657</td>\n",
       "      <td>0094320</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q869644</td>\n",
       "      <td>0083949</td>\n",
       "      <td>6.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81906</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Q6819873</td>\n",
       "      <td>1816585</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81907</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Ireland, United Kingdom]</td>\n",
       "      <td>[Biographical film, Drama, Documentary]</td>\n",
       "      <td>Q12125420</td>\n",
       "      <td>1606259</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81908</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Satire, Comedy]</td>\n",
       "      <td>Q4770308</td>\n",
       "      <td>0362411</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81909</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[Japanese Language]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>[Science Fiction, Japanese Movies, Adventure, ...</td>\n",
       "      <td>Q2663931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>12476867</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[Canada]</td>\n",
       "      <td>[Thriller, Horror, Slasher, Teen]</td>\n",
       "      <td>Q7578560</td>\n",
       "      <td>0354216</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81911 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_wikipedia_id                                    cmu_movie_title  \\\n",
       "0                  975900                                     Ghosts of Mars   \n",
       "1                 3196793  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2                28463795                                        Brun bitter   \n",
       "3                 9363483                                   White Of The Eye   \n",
       "4                  261236                                  A Woman in Flames   \n",
       "...                   ...                                                ...   \n",
       "81906            35228177                           Mermaids: The Body Found   \n",
       "81907            34980460                                            Knuckle   \n",
       "81908             9971909                                  Another Nice Mess   \n",
       "81909              913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "81910            12476867                                            Spliced   \n",
       "\n",
       "       movie_box_office_revenue  runtime       movie_languages  \\\n",
       "0                    14010832.0     98.0    [English Language]   \n",
       "1                           NaN     95.0    [English Language]   \n",
       "2                           NaN     83.0  [Norwegian Language]   \n",
       "3                           NaN    110.0    [English Language]   \n",
       "4                           NaN    106.0     [German Language]   \n",
       "...                         ...      ...                   ...   \n",
       "81906                       NaN    120.0    [English Language]   \n",
       "81907                       NaN     96.0    [English Language]   \n",
       "81908                       NaN     66.0    [English Language]   \n",
       "81909                       NaN    150.0   [Japanese Language]   \n",
       "81910                       NaN     86.0    [English Language]   \n",
       "\n",
       "                  movie_countries  \\\n",
       "0      [United States of America]   \n",
       "1      [United States of America]   \n",
       "2                        [Norway]   \n",
       "3                [United Kingdom]   \n",
       "4                       [Germany]   \n",
       "...                           ...   \n",
       "81906  [United States of America]   \n",
       "81907   [Ireland, United Kingdom]   \n",
       "81908  [United States of America]   \n",
       "81909                     [Japan]   \n",
       "81910                    [Canada]   \n",
       "\n",
       "                                            movie_genres movie_wikidata_id  \\\n",
       "0      [Thriller, Science Fiction, Horror, Adventure,...           Q261700   \n",
       "1       [Mystery, Biographical film, Drama, Crime Drama]         Q16250726   \n",
       "2                                 [Crime Fiction, Drama]          Q4978832   \n",
       "3      [Thriller, Erotic thriller, Psychological thri...          Q7995657   \n",
       "4                                                [Drama]           Q869644   \n",
       "...                                                  ...               ...   \n",
       "81906                                            [Drama]          Q6819873   \n",
       "81907            [Biographical film, Drama, Documentary]         Q12125420   \n",
       "81908                                   [Satire, Comedy]          Q4770308   \n",
       "81909  [Science Fiction, Japanese Movies, Adventure, ...          Q2663931   \n",
       "81910                  [Thriller, Horror, Slasher, Teen]          Q7578560   \n",
       "\n",
       "       imdb_id  movie_rating  numVotes  movie_release_year  \n",
       "0      0228333           4.9   56854.0                2001  \n",
       "1      0245916           6.0      69.0                2000  \n",
       "2      0094806           5.6      40.0                1988  \n",
       "3      0094320           6.1    2888.0                1987  \n",
       "4      0083949           6.0     621.0                1983  \n",
       "...        ...           ...       ...                 ...  \n",
       "81906  1816585           4.6    1710.0                2011  \n",
       "81907  1606259           6.8    3191.0                2011  \n",
       "81908  0362411           5.8     110.0                1972  \n",
       "81909      NaN           NaN       NaN                1992  \n",
       "81910  0354216           4.3    1766.0                2002  \n",
       "\n",
       "[81911 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column with movie release year to the dataframe\n",
    "\n",
    "# Keep only year in the string 'year-month-day'\n",
    "final_movie_df['movie_release_year'] = final_movie_df['movie_release_date'].str.split('-').str[0].astype(\"Int32\")\n",
    "\n",
    "# Drop the 'movie_release_date' column\n",
    "final_movie_df.drop('movie_release_date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final movie dataframe is ready ! Let's save it for the analysis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_df.to_csv('data/final_movie_metadata.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
